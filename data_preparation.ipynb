{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from IPython.core.display_functions import display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from collections import Counter\n",
    "from scipy import stats\n",
    "from scipy.stats import boxcox, yeojohnson\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_selection import SelectKBest,f_classif\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score\n",
    "import optuna\n",
    "from optuna.samplers import CmaEsSampler\n",
    "from optuna.samplers import RandomSampler\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from optuna.samplers import TPESampler\n",
    "from sklearn.metrics import f1_score, roc_auc_score\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.utils import resample\n",
    "from sklearn.decomposition import PCA"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "outputs": [],
   "source": [
    "from main import read_xlsb\n",
    "\n",
    "# download data\n",
    "train_data_path = \"./data/Training.xlsb\"\n",
    "train_sheet_name = 'Training'  # Укажите имя листа, который хотите прочитать\n",
    "train_data = read_xlsb(train_data_path, train_sheet_name)\n",
    "\n",
    "test_data_path = \"./data/Test.xlsb\"\n",
    "test_sheet_name = 'Test'  # Укажите имя листа, который хотите прочитать\n",
    "test_data = read_xlsb(test_data_path, test_sheet_name)\n",
    "\n",
    "# создание train test dataframe\n",
    "train_data_copy = train_data.copy()\n",
    "test_data_copy = test_data.copy()\n",
    "X = train_data_copy.drop([\"MARKER\",\"ID\"],axis = 1)\n",
    "X_test = test_data_copy.drop([\"MARKER\",\"ID\"],axis = 1)\n",
    "y = train_data_copy['MARKER']\n",
    "y_test = test_data_copy['MARKER']\n",
    "\n",
    "#создание копий\n",
    "X_copy = X.copy()\n",
    "y_copy= y.copy()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID         A         B       C       D         E         F     G  \\\n",
      "0          1.0  0.198778  0.099389    0.00  799.90  1.777556  0.888778  13.0   \n",
      "1          2.0  0.043000  0.021264   49.97  173.03  0.384511  0.190143  13.0   \n",
      "2          3.0  0.067073  0.067073    0.00  329.90  0.599818  0.599818  13.0   \n",
      "3          4.0  0.052700  0.052700    0.00  235.65  0.471300  0.471300  13.0   \n",
      "4          5.0  0.141880  0.141880    0.00  634.45  1.268900  1.268900  13.0   \n",
      "...        ...       ...       ...     ...     ...       ...       ...   ...   \n",
      "89729  89730.0  0.027941  0.014844   25.00  474.00  0.557647  0.296250  20.0   \n",
      "89730  89731.0  0.120017  0.068581  179.96  720.03  1.200050  0.685743  10.0   \n",
      "89731  89732.0  0.153033  0.122427   29.01  550.99  0.459158  0.367327   3.0   \n",
      "89732  89733.0  0.107575  0.043030   53.82  215.18  0.537950  0.215180   5.0   \n",
      "89733  89734.0  0.095750  0.095750   57.48  172.42  0.287367  0.287367   3.0   \n",
      "\n",
      "          H      I  ...       P          Q    R          S    T    U    V  \\\n",
      "0      3.49  Woman  ...   2 Two   property   No      Works  Yes  Yes   No   \n",
      "1      3.49  Woman  ...   2 Two  otherwise   No      Works  Yes  Yes  Yes   \n",
      "2      3.49  Woman  ...   1 One   property   No  No couple   No  Yes   No   \n",
      "3      3.49  Woman  ...  0 Zero   property   No  No couple  Yes  Yes  Few   \n",
      "4      3.49  Woman  ...  0 Zero   property   No  No couple  Yes   No   No   \n",
      "...     ...    ...  ...     ...        ...  ...        ...  ...  ...  ...   \n",
      "89729  0.01    Man  ...  0 Zero   property   No      Works  Yes  Yes   No   \n",
      "89730  0.00  Woman  ...   2 Two   property   No      Works  Yes  Yes   No   \n",
      "89731  0.00    Man  ...  0 Zero  otherwise   No      Works  Yes  Yes   No   \n",
      "89732  0.00  Woman  ...   1 One   property  Yes      Works   No  Yes   No   \n",
      "89733  0.00    Man  ...  0 Zero  otherwise   No  No couple   No  Yes   No   \n",
      "\n",
      "         W    X MARKER  \n",
      "0      Yes   No    0.0  \n",
      "1      Yes   No    0.0  \n",
      "2      Yes   No    0.0  \n",
      "3      Yes   No    0.0  \n",
      "4       No   No    0.0  \n",
      "...    ...  ...    ...  \n",
      "89729   No  Yes    0.0  \n",
      "89730   No  Yes    0.0  \n",
      "89731  Yes  Yes    0.0  \n",
      "89732   No  Yes    0.0  \n",
      "89733   No  Yes    0.0  \n",
      "\n",
      "[89734 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# удаление дублирующих строк\n",
    "train_data_copy = train_data_copy.drop_duplicates()\n",
    "print(train_data_copy)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID         A         B       C       D         E         F     G  \\\n",
      "0          1.0  0.198778  0.099389    0.00  799.90  1.777556  0.888778  13.0   \n",
      "1          2.0  0.043000  0.021264   49.97  173.03  0.384511  0.190143  13.0   \n",
      "2          3.0  0.067073  0.067073    0.00  329.90  0.599818  0.599818  13.0   \n",
      "3          4.0  0.052700  0.052700    0.00  235.65  0.471300  0.471300  13.0   \n",
      "4          5.0  0.141880  0.141880    0.00  634.45  1.268900  1.268900  13.0   \n",
      "...        ...       ...       ...     ...     ...       ...       ...   ...   \n",
      "89729  89730.0  0.027941  0.014844   25.00  474.00  0.557647  0.296250  20.0   \n",
      "89730  89731.0  0.120017  0.068581  179.96  720.03  1.200050  0.685743  10.0   \n",
      "89731  89732.0  0.153033  0.122427   29.01  550.99  0.459158  0.367327   3.0   \n",
      "89732  89733.0  0.107575  0.043030   53.82  215.18  0.537950  0.215180   5.0   \n",
      "89733  89734.0  0.095750  0.095750   57.48  172.42  0.287367  0.287367   3.0   \n",
      "\n",
      "          H  I  ...  P      Q  R      S  T  U      V  W  X  MARKER  \n",
      "0      3.49  1  ...  2  81457  0  47413  1  1  78462  1  0     0.0  \n",
      "1      3.49  1  ...  2   6679  0  47413  1  1  10561  1  0     0.0  \n",
      "2      3.49  1  ...  1  81457  0  26457  0  1  78462  1  0     0.0  \n",
      "3      3.49  1  ...  0  81457  0  26457  1  1    711  1  0     0.0  \n",
      "4      3.49  1  ...  0  81457  0  26457  1  0  78462  0  0     0.0  \n",
      "...     ... ..  ... ..    ... ..    ... .. ..    ... .. ..     ...  \n",
      "89729  0.01  0  ...  0  81457  0  47413  1  1  78462  0  1     0.0  \n",
      "89730  0.00  1  ...  2  81457  0  47413  1  1  78462  0  1     0.0  \n",
      "89731  0.00  0  ...  0   6679  0  47413  1  1  78462  1  1     0.0  \n",
      "89732  0.00  1  ...  1  81457  1  47413  0  1  78462  0  1     0.0  \n",
      "89733  0.00  0  ...  0   6679  0  26457  0  1  78462  0  1     0.0  \n",
      "\n",
      "[89734 rows x 26 columns]\n",
      "            ID         A         B       C        D         E         F     G  \\\n",
      "0          1.0  0.085400  0.085400   29.72   267.28  0.763657  0.763657  13.0   \n",
      "1          2.0  0.223218  0.111609    0.00  1097.90  1.996182  0.998091  13.0   \n",
      "2          3.0  0.048400  0.048400    0.00   399.90  0.499875  0.499875  13.0   \n",
      "3          4.0  0.039560  0.039560   19.59   176.93  0.353860  0.353860  13.0   \n",
      "4          5.0  0.231017  0.173263    0.00  1239.56  2.065933  1.549450  13.0   \n",
      "...        ...       ...       ...     ...      ...       ...       ...   ...   \n",
      "38400  38401.0  0.569320  0.237217   44.95   854.05  1.708100  0.711708   3.0   \n",
      "38401  38402.0  0.072727  0.072727   45.86   413.14  0.751164  0.751164  13.0   \n",
      "38402  38403.0  0.095750  0.095750   57.48   172.42  0.287367  0.287367   3.0   \n",
      "38403  38404.0  0.042287  0.042287  422.00  1266.00  0.844000  0.844000  20.0   \n",
      "38404  38405.0  0.169175  0.169175   17.82   338.38  0.845950  0.845950   5.0   \n",
      "\n",
      "          H  I  ...  P      Q  R      S  T  U      V  W  X  MARKER  \n",
      "0      3.49  1  ...  1  34820  0  11285  1  1  33661  0  0     0.0  \n",
      "1      3.49  1  ...  3  34820  0  20266  1  1  33661  0  0     1.0  \n",
      "2      1.99  0  ...  0  34820  0   4834  1  1  33661  0  0     0.0  \n",
      "3      3.49  0  ...  1  34820  0   4834  1  1   4446  1  0     0.0  \n",
      "4      3.49  1  ...  1  34820  0  20266  1  1  33661  0  0     0.0  \n",
      "...     ... ..  ... ..    ... ..    ... .. ..    ... .. ..     ...  \n",
      "38400  0.00  0  ...  0  34820  0  20266  1  0  33661  0  1     0.0  \n",
      "38401  1.99  1  ...  0  34820  0  11285  1  1  33661  0  1     0.0  \n",
      "38402  0.00  1  ...  0    745  1  11285  0  1  33661  1  1     0.0  \n",
      "38403  0.01  1  ...  1  34820  1  11285  1  1  33661  0  1     0.0  \n",
      "38404  0.00  0  ...  0  34820  0   4834  1  1  33661  0  1     0.0  \n",
      "\n",
      "[38405 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# кодирование категориальных признаков\n",
    "def encode_categorical_features(df):\n",
    "    encoded_df = df.copy()\n",
    "\n",
    "    # Шаг 1: Выбор категориальных признаков\n",
    "    categorical_columns = df.select_dtypes(include=['object']).columns\n",
    "\n",
    "    # Шаг 2: Закодировать категориальные признаки\n",
    "    for column in categorical_columns:\n",
    "        unique_values = df[column].nunique()\n",
    "        if column == 'P':\n",
    "            # Отдельный метод для столбца 'P'\n",
    "            encoded_values = {\n",
    "                '0 Zero': 0,\n",
    "                '1 One': 1,\n",
    "                '2 Two': 2,\n",
    "                '3 Three': 3,\n",
    "                'More than 3': 4\n",
    "            }\n",
    "            encoded_df[column] = df[column].map(encoded_values)\n",
    "        elif unique_values <= 2:\n",
    "            # One-hot encoding для признаков с <= 2 уникальными значениями\n",
    "            encoder = LabelEncoder()\n",
    "            encoded_df[column] = encoder.fit_transform(df[column])\n",
    "        else:\n",
    "            # Count encoding для признаков с > 2 уникальными значениями\n",
    "            counter = df[column].value_counts().to_dict()\n",
    "            encoded_df[column] = df[column].map(counter)\n",
    "\n",
    "    return encoded_df\n",
    "\n",
    "\n",
    "train_data_copy[X.columns] = encode_categorical_features(train_data_copy[X.columns])\n",
    "print(train_data_copy)\n",
    "train_data_copy.to_csv('encoded_train_data.csv')\n",
    "\n",
    "test_data_copy[X_test.columns] = encode_categorical_features(test_data_copy[X_test.columns])\n",
    "print(test_data_copy)\n",
    "test_data_copy.to_csv('encoded_test_data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\ndef normalize_columns(df, small_value=1e-10):\\n    normalized_df = pd.DataFrame()\\n\\n    for column in df.columns:\\n        data = df[column]\\n\\n        # Применение всех перечисленных методов нормализации\\n        methods = [\\n            (np.log1p,),\\n            (lambda x: 1 / (x + small_value) if (x != 0).all() else x,),\\n            (np.sqrt,),\\n            (np.square,),\\n            (boxcox,),\\n            (yeojohnson,),\\n            (boxcox, yeojohnson),\\n            (np.log1p, boxcox),\\n            (np.log1p, yeojohnson),\\n            (np.log1p, boxcox, yeojohnson)\\n        ]\\n\\n        # Переменные для выбора наилучшей комбинации методов\\n        best_methods = None\\n        best_p_value = 0.0\\n\\n        for method_group in methods:\\n            transformed_data = data\\n\\n            for method in method_group:\\n                if method in [boxcox, yeojohnson]:\\n                    if (transformed_data == 0).any():\\n                        transformed_data, _ = method(transformed_data + small_value)\\n                    else:\\n                        transformed_data, _ = method(transformed_data)\\n                else:\\n                    transformed_data = method(transformed_data)\\n\\n            _, p_value = stats.normaltest(transformed_data)\\n            print(\"столбец:\",column,\"метод:\",method,\"текущий p_value:\",p_value)\\n            if p_value > best_p_value:\\n                best_p_value = p_value\\n                best_methods = method_group\\n\\n        # Применение наилучшей комбинации методов к столбцу\\n        transformed_data = data\\n\\n        if best_methods:\\n            for method in best_methods:\\n                if method in [boxcox, yeojohnson]:\\n                    if (transformed_data == 0).any():\\n                        transformed_data, _ = method(transformed_data + small_value)\\n                    else:\\n                        transformed_data, _ = method(transformed_data)\\n                else:\\n                    transformed_data = method(transformed_data)\\n\\n        normalized_df[column] = transformed_data\\n\\n    return normalized_df\\n\\nX_copy = normalize_columns(X_copy)\\nprint(X_copy)\\n'"
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "def normalize_columns(df, small_value=1e-10):\n",
    "    normalized_df = pd.DataFrame()\n",
    "\n",
    "    for column in df.columns:\n",
    "        data = df[column]\n",
    "\n",
    "        # Применение всех перечисленных методов нормализации\n",
    "        methods = [\n",
    "            (np.log1p,),\n",
    "            (lambda x: 1 / (x + small_value) if (x != 0).all() else x,),\n",
    "            (np.sqrt,),\n",
    "            (np.square,),\n",
    "            (boxcox,),\n",
    "            (yeojohnson,),\n",
    "            (boxcox, yeojohnson),\n",
    "            (np.log1p, boxcox),\n",
    "            (np.log1p, yeojohnson),\n",
    "            (np.log1p, boxcox, yeojohnson)\n",
    "        ]\n",
    "\n",
    "        # Переменные для выбора наилучшей комбинации методов\n",
    "        best_methods = None\n",
    "        best_p_value = 0.0\n",
    "\n",
    "        for method_group in methods:\n",
    "            transformed_data = data\n",
    "\n",
    "            for method in method_group:\n",
    "                if method in [boxcox, yeojohnson]:\n",
    "                    if (transformed_data == 0).any():\n",
    "                        transformed_data, _ = method(transformed_data + small_value)\n",
    "                    else:\n",
    "                        transformed_data, _ = method(transformed_data)\n",
    "                else:\n",
    "                    transformed_data = method(transformed_data)\n",
    "\n",
    "            _, p_value = stats.normaltest(transformed_data)\n",
    "            print(\"столбец:\",column,\"метод:\",method,\"текущий p_value:\",p_value)\n",
    "            if p_value > best_p_value:\n",
    "                best_p_value = p_value\n",
    "                best_methods = method_group\n",
    "\n",
    "        # Применение наилучшей комбинации методов к столбцу\n",
    "        transformed_data = data\n",
    "\n",
    "        if best_methods:\n",
    "            for method in best_methods:\n",
    "                if method in [boxcox, yeojohnson]:\n",
    "                    if (transformed_data == 0).any():\n",
    "                        transformed_data, _ = method(transformed_data + small_value)\n",
    "                    else:\n",
    "                        transformed_data, _ = method(transformed_data)\n",
    "                else:\n",
    "                    transformed_data = method(transformed_data)\n",
    "\n",
    "        normalized_df[column] = transformed_data\n",
    "\n",
    "    return normalized_df\n",
    "\n",
    "X_copy = normalize_columns(X_copy)\n",
    "print(X_copy)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "len train_data input 89734\n",
      "len train_data_cleaned 87350\n",
      "Deleted rows from class 0: 2366\n",
      "Deleted rows from class 1: 18\n",
      "            ID         A         B       C       D         E         F     G  \\\n",
      "0          1.0  0.198778  0.099389    0.00  799.90  1.777556  0.888778  13.0   \n",
      "1          2.0  0.043000  0.021264   49.97  173.03  0.384511  0.190143  13.0   \n",
      "2          3.0  0.067073  0.067073    0.00  329.90  0.599818  0.599818  13.0   \n",
      "3          4.0  0.052700  0.052700    0.00  235.65  0.471300  0.471300  13.0   \n",
      "4          5.0  0.141880  0.141880    0.00  634.45  1.268900  1.268900  13.0   \n",
      "...        ...       ...       ...     ...     ...       ...       ...   ...   \n",
      "89729  89730.0  0.027941  0.014844   25.00  474.00  0.557647  0.296250  20.0   \n",
      "89730  89731.0  0.120017  0.068581  179.96  720.03  1.200050  0.685743  10.0   \n",
      "89731  89732.0  0.153033  0.122427   29.01  550.99  0.459158  0.367327   3.0   \n",
      "89732  89733.0  0.107575  0.043030   53.82  215.18  0.537950  0.215180   5.0   \n",
      "89733  89734.0  0.095750  0.095750   57.48  172.42  0.287367  0.287367   3.0   \n",
      "\n",
      "          H  I  ...  P      Q  R      S  T  U      V  W  X  MARKER  \n",
      "0      3.49  1  ...  2  81457  0  47413  1  1  78462  1  0     0.0  \n",
      "1      3.49  1  ...  2   6679  0  47413  1  1  10561  1  0     0.0  \n",
      "2      3.49  1  ...  1  81457  0  26457  0  1  78462  1  0     0.0  \n",
      "3      3.49  1  ...  0  81457  0  26457  1  1    711  1  0     0.0  \n",
      "4      3.49  1  ...  0  81457  0  26457  1  0  78462  0  0     0.0  \n",
      "...     ... ..  ... ..    ... ..    ... .. ..    ... .. ..     ...  \n",
      "89729  0.01  0  ...  0  81457  0  47413  1  1  78462  0  1     0.0  \n",
      "89730  0.00  1  ...  2  81457  0  47413  1  1  78462  0  1     0.0  \n",
      "89731  0.00  0  ...  0   6679  0  47413  1  1  78462  1  1     0.0  \n",
      "89732  0.00  1  ...  1  81457  1  47413  0  1  78462  0  1     0.0  \n",
      "89733  0.00  0  ...  0   6679  0  26457  0  1  78462  0  1     0.0  \n",
      "\n",
      "[87350 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "def remove_outliers(train_data, num_columns_threshold=5, ignore_columns=[], remove_class_1_outliers=True):\n",
    "    print(\"len train_data input\", len(train_data))\n",
    "    # Выбираем только столбцы, которые не находятся в списке ignore_columns\n",
    "    columns_to_analyze = [col for col in train_data.columns if col not in ignore_columns]\n",
    "    df = train_data[columns_to_analyze]\n",
    "\n",
    "    # Подсчитываем Q1 и Q3 для каждого столбца\n",
    "    q1 = df.quantile(0.25)\n",
    "    q3 = df.quantile(0.75)\n",
    "\n",
    "    # Рассчитываем межквартильный размах (IQR)\n",
    "    iqr = q3 - q1\n",
    "\n",
    "    # Определяем границы интервала для удаления выбросов\n",
    "    lower_bound = q1 - 1.5 * iqr\n",
    "    upper_bound = q3 + 1.5 * iqr\n",
    "\n",
    "    # Создаем маску для определения строк с выбросами в каждом столбце\n",
    "    outliers_mask = ((df < lower_bound) | (df > upper_bound))\n",
    "\n",
    "    # Подсчитываем количество столбцов с выбросами в каждой строке\n",
    "    num_outliers = outliers_mask.sum(axis=1)\n",
    "\n",
    "    # Создаем маску для определения строк с выбросами в 5 и более столбцах\n",
    "    mask = (num_outliers >= num_columns_threshold)\n",
    "\n",
    "    # Удаляем строки с выбросами из train_data\n",
    "    if remove_class_1_outliers:\n",
    "        mask_to_remove = mask\n",
    "    else:\n",
    "        mask_to_remove = mask & (train_data['MARKER'] != 1)\n",
    "    train_data_cleaned = train_data[~mask_to_remove]\n",
    "\n",
    "    print(\"len train_data_cleaned\", len(train_data_cleaned))\n",
    "    # Подсчитываем количество удаленных строк для каждого класса\n",
    "    num_deleted_class_0 = len(train_data[train_data['MARKER'] == 0]) - len(train_data_cleaned[train_data_cleaned['MARKER'] == 0])\n",
    "    num_deleted_class_1 = len(train_data[train_data['MARKER'] == 1]) - len(train_data_cleaned[train_data_cleaned['MARKER'] == 1])\n",
    "    print(\"Deleted rows from class 0:\", num_deleted_class_0)\n",
    "    print(\"Deleted rows from class 1:\", num_deleted_class_1)\n",
    "\n",
    "    return train_data_cleaned\n",
    "\n",
    "# Пример использования функции с удалением строк из класса MARKER = 1\n",
    "train_data_copy = remove_outliers(train_data_copy, num_columns_threshold=5, ignore_columns=['ID', 'MARKER'], remove_class_1_outliers=True)\n",
    "print(train_data_copy)\n",
    "train_data_copy.to_csv('remove_outliers_train_data.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\ntrain_data_copy = robust_scale_dataframe(train_data_copy,ignore_columns=['ID', 'MARKER'])\\nprint(train_data_copy)\\ntrain_data_copy.to_csv('prepar_train_data.csv')\\n\\ntest_data_copy = robust_scale_dataframe(test_data_copy,ignore_columns=['ID', 'MARKER'])\\nprint(test_data_copy)\\ntest_data_copy.to_csv('prepar_test_data.csv')\\n\""
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# масштабирование\n",
    "def robust_scale_dataframe(df, ignore_columns=[]):\n",
    "    columns_to_scale = [col for col in df.columns if col not in ignore_columns]\n",
    "    scaler = RobustScaler()\n",
    "    scaled_data = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "    # Обновляем значения в столбцах, которые нужно масштабировать\n",
    "    df.loc[:, columns_to_scale] = scaled_data\n",
    "    return df\n",
    "\"\"\"\n",
    "train_data_copy = robust_scale_dataframe(train_data_copy,ignore_columns=['ID', 'MARKER'])\n",
    "print(train_data_copy)\n",
    "train_data_copy.to_csv('prepar_train_data.csv')\n",
    "\n",
    "test_data_copy = robust_scale_dataframe(test_data_copy,ignore_columns=['ID', 'MARKER'])\n",
    "print(test_data_copy)\n",
    "test_data_copy.to_csv('prepar_test_data.csv')\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID         A         B         C         D         E         F  \\\n",
      "0          1.0  0.260126 -0.096338 -0.851553  0.650218  1.024437  0.448462   \n",
      "1          2.0 -0.829576 -0.893296 -0.330364 -0.843031 -0.719023 -0.837314   \n",
      "2          3.0 -0.661182 -0.425997 -0.851553 -0.469356 -0.449556 -0.083343   \n",
      "3          4.0 -0.761722 -0.572614 -0.851553 -0.693866 -0.610402 -0.319869   \n",
      "4          5.0 -0.137887  0.337116 -0.851553  0.256104  0.387831  1.148043   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "89729  89730.0 -0.934916 -0.958787 -0.590802 -0.126099 -0.502335 -0.642033   \n",
      "89730  89731.0 -0.290827 -0.410611  1.025437  0.459962  0.301662  0.074794   \n",
      "89731  89732.0 -0.059867  0.138671 -0.548978  0.057296 -0.625598 -0.511223   \n",
      "89732  89733.0 -0.377859 -0.671258 -0.290208 -0.742627 -0.526987 -0.791235   \n",
      "89733  89734.0 -0.460577 -0.133459 -0.252035 -0.844484 -0.840603 -0.658382   \n",
      "\n",
      "              G         H         I  ...         P         Q         R  \\\n",
      "0      1.099090  3.209027  0.913155  ...  1.390837  0.311910 -0.447115   \n",
      "1      1.099090  3.209027  0.913155  ...  1.390837 -3.158734 -0.447115   \n",
      "2      1.099090  3.209027  0.913155  ...  0.262842  0.311910 -0.447115   \n",
      "3      1.099090  3.209027  0.913155  ... -0.865154  0.311910 -0.447115   \n",
      "4      1.099090  3.209027  0.913155  ... -0.865154  0.311910 -0.447115   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "89729  2.579008 -0.539453 -1.095105  ... -0.865154  0.311910 -0.447115   \n",
      "89730  0.464839 -0.550224  0.913155  ...  1.390837  0.311910 -0.447115   \n",
      "89731 -1.015080 -0.550224 -1.095105  ... -0.865154 -3.158734 -0.447115   \n",
      "89732 -0.592246 -0.550224  0.913155  ...  0.262842  0.311910  2.236560   \n",
      "89733 -1.015080 -0.550224 -1.095105  ... -0.865154 -3.158734 -0.447115   \n",
      "\n",
      "              S         T         U         V         W         X  MARKER  \n",
      "0      0.862514  0.427892  0.407722  0.372731  1.161248 -0.790758     0.0  \n",
      "1      0.862514  0.427892  0.407722 -2.651729  1.161248 -0.790758     0.0  \n",
      "2     -0.546098 -2.337040  0.407722  0.372731  1.161248 -0.790758     0.0  \n",
      "3     -0.546098  0.427892  0.407722 -3.090469  1.161248 -0.790758     0.0  \n",
      "4     -0.546098  0.427892 -2.452652  0.372731 -0.861142 -0.790758     0.0  \n",
      "...         ...       ...       ...       ...       ...       ...     ...  \n",
      "89729  0.862514  0.427892  0.407722  0.372731 -0.861142  1.264610     0.0  \n",
      "89730  0.862514  0.427892  0.407722  0.372731 -0.861142  1.264610     0.0  \n",
      "89731  0.862514  0.427892  0.407722  0.372731  1.161248  1.264610     0.0  \n",
      "89732  0.862514 -2.337040  0.407722  0.372731 -0.861142  1.264610     0.0  \n",
      "89733 -0.546098 -2.337040  0.407722  0.372731 -0.861142  1.264610     0.0  \n",
      "\n",
      "[87350 rows x 26 columns]\n",
      "            ID         A         B         C         D         E         F  \\\n",
      "0          1.0 -0.537304 -0.258903 -0.528232 -0.623304 -0.267175  0.131267   \n",
      "1          2.0  0.387210 -0.007078 -0.809791  1.204640  1.082230  0.507430   \n",
      "2          3.0 -0.785508 -0.614411 -0.809791 -0.331448 -0.555972 -0.291988   \n",
      "3          4.0 -0.844809 -0.699348 -0.624201 -0.822137 -0.715833 -0.526278   \n",
      "4          5.0  0.439524  0.585306 -0.809791  1.516391  1.158596  1.392120   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "38400  38401.0  2.708937  1.199797 -0.383947  0.668000  0.766830  0.047912   \n",
      "38401  38402.0 -0.622316 -0.380667 -0.375326 -0.302310 -0.280853  0.111220   \n",
      "38402  38403.0 -0.467874 -0.159457 -0.265241 -0.832063 -0.788632 -0.632970   \n",
      "38403  38404.0 -0.826518 -0.673149  3.188120  1.574578 -0.179213  0.260182   \n",
      "38404  38405.0  0.024677  0.546032 -0.640969 -0.466835 -0.177078  0.263311   \n",
      "\n",
      "              G         H         I  ...         P         Q         R  \\\n",
      "0      1.058852  3.182894  0.924783  ...  0.259791  0.320749 -0.456454   \n",
      "1      1.058852  3.182894  0.924783  ...  2.509711  0.320749 -0.456454   \n",
      "2      1.058852  1.577155 -1.081334  ... -0.865169  0.320749 -0.456454   \n",
      "3      1.058852  3.182894 -1.081334  ...  0.259791  0.320749 -0.456454   \n",
      "4      1.058852  3.182894  0.924783  ...  0.259791  0.320749 -0.456454   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "38400 -1.023521 -0.553125 -1.081334  ... -0.865169  0.320749 -0.456454   \n",
      "38401  1.058852  1.577155  0.924783  ... -0.865169  0.320749 -0.456454   \n",
      "38402 -1.023521 -0.553125  0.924783  ... -0.865169 -3.291263  2.190801   \n",
      "38403  2.516513 -0.542420  0.924783  ...  0.259791  0.320749  2.190801   \n",
      "38404 -0.607047 -0.553125 -1.081334  ... -0.865169  0.320749 -0.456454   \n",
      "\n",
      "              S         T         U         V         W         X  MARKER  \n",
      "0     -0.539709  0.440791  0.413165  0.375163 -0.863712 -0.789346     0.0  \n",
      "1      0.870528  0.440791  0.413165  0.375163 -0.863712 -0.789346     1.0  \n",
      "2     -1.552675  0.440791  0.413165  0.375163 -0.863712 -0.789346     0.0  \n",
      "3     -1.552675  0.440791  0.413165 -2.635118  1.157793 -0.789346     0.0  \n",
      "4      0.870528  0.440791  0.413165  0.375163 -0.863712 -0.789346     0.0  \n",
      "...         ...       ...       ...       ...       ...       ...     ...  \n",
      "38400  0.870528  0.440791 -2.420338  0.375163 -0.863712  1.266872     0.0  \n",
      "38401 -0.539709  0.440791  0.413165  0.375163 -0.863712  1.266872     0.0  \n",
      "38402 -0.539709 -2.268649  0.413165  0.375163  1.157793  1.266872     0.0  \n",
      "38403 -0.539709  0.440791  0.413165  0.375163 -0.863712  1.266872     0.0  \n",
      "38404 -1.552675  0.440791  0.413165  0.375163 -0.863712  1.266872     0.0  \n",
      "\n",
      "[38405 rows x 26 columns]\n"
     ]
    }
   ],
   "source": [
    "# масштабирование с выбором способа\n",
    "def scale_dataframe(df, ignore_columns=[], scaler_type='robust'):\n",
    "    columns_to_scale = [col for col in df.columns if col not in ignore_columns]\n",
    "\n",
    "    if scaler_type == 'standard':\n",
    "        scaler = StandardScaler()\n",
    "    elif scaler_type == 'robust':\n",
    "        scaler = RobustScaler()\n",
    "    else:\n",
    "        raise ValueError(\"Invalid scaler_type. Use 'standard' or 'robust'.\")\n",
    "\n",
    "    scaled_data = scaler.fit_transform(df[columns_to_scale])\n",
    "\n",
    "    # Обновляем значения в столбцах, которые нужно масштабировать\n",
    "    df.loc[:, columns_to_scale] = scaled_data\n",
    "    return df\n",
    "\n",
    "# Пример использования с разными способами масштабирования\n",
    "train_data_copy = scale_dataframe(train_data_copy,ignore_columns=['ID', 'MARKER'],scaler_type= \"standard\")\n",
    "print(train_data_copy)\n",
    "train_data_copy.to_csv('prepar_train_data.csv')\n",
    "\n",
    "test_data_copy = scale_dataframe(test_data_copy,ignore_columns=['ID', 'MARKER'],scaler_type= \"standard\")\n",
    "print(test_data_copy)\n",
    "test_data_copy.to_csv('prepar_test_data.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            ID         A         B         C         D         E         F  \\\n",
      "0          1.0  0.260126 -0.096338 -0.851553  0.650218  1.024437  0.448462   \n",
      "1          2.0 -0.829576 -0.893296 -0.330364 -0.843031 -0.719023 -0.837314   \n",
      "2          3.0 -0.661182 -0.425997 -0.851553 -0.469356 -0.449556 -0.083343   \n",
      "3          4.0 -0.761722 -0.572614 -0.851553 -0.693866 -0.610402 -0.319869   \n",
      "4          5.0 -0.137887  0.337116 -0.851553  0.256104  0.387831  1.148043   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "89729  89730.0 -0.934916 -0.958787 -0.590802 -0.126099 -0.502335 -0.642033   \n",
      "89730  89731.0 -0.290827 -0.410611  1.025437  0.459962  0.301662  0.074794   \n",
      "89731  89732.0 -0.059867  0.138671 -0.548978  0.057296 -0.625598 -0.511223   \n",
      "89732  89733.0 -0.377859 -0.671258 -0.290208 -0.742627 -0.526987 -0.791235   \n",
      "89733  89734.0 -0.460577 -0.133459 -0.252035 -0.844484 -0.840603 -0.658382   \n",
      "\n",
      "              G         H         I  ...         M         N         O  \\\n",
      "0      1.099090  3.209027  0.913155  ...  0.474695  0.710451  0.642038   \n",
      "1      1.099090  3.209027  0.913155  ...  0.474695  0.710451  0.642038   \n",
      "2      1.099090  3.209027  0.913155  ...  0.474695  0.710451 -1.551003   \n",
      "3      1.099090  3.209027  0.913155  ... -2.072290  0.710451 -1.551003   \n",
      "4      1.099090  3.209027  0.913155  ...  0.474695  0.710451 -1.551003   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "89729  2.579008 -0.539453 -1.095105  ... -2.058774  0.710451  0.642038   \n",
      "89730  0.464839 -0.550224  0.913155  ...  0.474695 -1.247629  0.642038   \n",
      "89731 -1.015080 -0.550224 -1.095105  ...  0.474695 -1.247629  0.642038   \n",
      "89732 -0.592246 -0.550224  0.913155  ...  0.474695 -1.247629  0.642038   \n",
      "89733 -1.015080 -0.550224 -1.095105  ...  0.474695 -1.247629 -1.486774   \n",
      "\n",
      "              P         R         S         T         W         X  MARKER  \n",
      "0      1.390837 -0.447115  0.862514  0.427892  1.161248 -0.790758     0.0  \n",
      "1      1.390837 -0.447115  0.862514  0.427892  1.161248 -0.790758     0.0  \n",
      "2      0.262842 -0.447115 -0.546098 -2.337040  1.161248 -0.790758     0.0  \n",
      "3     -0.865154 -0.447115 -0.546098  0.427892  1.161248 -0.790758     0.0  \n",
      "4     -0.865154 -0.447115 -0.546098  0.427892 -0.861142 -0.790758     0.0  \n",
      "...         ...       ...       ...       ...       ...       ...     ...  \n",
      "89729 -0.865154 -0.447115  0.862514  0.427892 -0.861142  1.264610     0.0  \n",
      "89730  1.390837 -0.447115  0.862514  0.427892 -0.861142  1.264610     0.0  \n",
      "89731 -0.865154 -0.447115  0.862514  0.427892  1.161248  1.264610     0.0  \n",
      "89732  0.262842  2.236560  0.862514 -2.337040 -0.861142  1.264610     0.0  \n",
      "89733 -0.865154 -0.447115 -0.546098 -2.337040 -0.861142  1.264610     0.0  \n",
      "\n",
      "[87350 rows x 23 columns]\n",
      "            ID         A         C         D         E         G         H  \\\n",
      "0          1.0  0.260126 -0.851553  0.650218  1.024437  1.099090  3.209027   \n",
      "1          2.0 -0.829576 -0.330364 -0.843031 -0.719023  1.099090  3.209027   \n",
      "2          3.0 -0.661182 -0.851553 -0.469356 -0.449556  1.099090  3.209027   \n",
      "3          4.0 -0.761722 -0.851553 -0.693866 -0.610402  1.099090  3.209027   \n",
      "4          5.0 -0.137887 -0.851553  0.256104  0.387831  1.099090  3.209027   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "89729  89730.0 -0.934916 -0.590802 -0.126099 -0.502335  2.579008 -0.539453   \n",
      "89730  89731.0 -0.290827  1.025437  0.459962  0.301662  0.464839 -0.550224   \n",
      "89731  89732.0 -0.059867 -0.548978  0.057296 -0.625598 -1.015080 -0.550224   \n",
      "89732  89733.0 -0.377859 -0.290208 -0.742627 -0.526987 -0.592246 -0.550224   \n",
      "89733  89734.0 -0.460577 -0.252035 -0.844484 -0.840603 -1.015080 -0.550224   \n",
      "\n",
      "              I         J         K  ...         M         N         O  \\\n",
      "0      0.913155 -0.660309 -2.499166  ...  0.474695  0.710451  0.642038   \n",
      "1      0.913155 -0.705387  1.283535  ...  0.474695  0.710451  0.642038   \n",
      "2      0.913155 -0.224555 -0.323077  ...  0.474695  0.710451 -1.551003   \n",
      "3      0.913155  1.818981  1.283535  ... -2.072290  0.710451 -1.551003   \n",
      "4      0.913155  0.677005  0.468389  ...  0.474695  0.710451 -1.551003   \n",
      "...         ...       ...       ...  ...       ...       ...       ...   \n",
      "89729 -1.095105 -1.283888  1.283535  ... -2.058774  0.710451  0.642038   \n",
      "89730  0.913155  0.316381  0.536466  ...  0.474695 -1.247629  0.642038   \n",
      "89731 -1.095105  1.818981  0.536466  ...  0.474695 -1.247629  0.642038   \n",
      "89732  0.913155 -1.103576  0.536466  ...  0.474695 -1.247629  0.642038   \n",
      "89733 -1.095105 -0.953316  0.536466  ...  0.474695 -1.247629 -1.486774   \n",
      "\n",
      "              P         R         S         T         W         X  MARKER  \n",
      "0      1.390837 -0.447115  0.862514  0.427892  1.161248 -0.790758     0.0  \n",
      "1      1.390837 -0.447115  0.862514  0.427892  1.161248 -0.790758     0.0  \n",
      "2      0.262842 -0.447115 -0.546098 -2.337040  1.161248 -0.790758     0.0  \n",
      "3     -0.865154 -0.447115 -0.546098  0.427892  1.161248 -0.790758     0.0  \n",
      "4     -0.865154 -0.447115 -0.546098  0.427892 -0.861142 -0.790758     0.0  \n",
      "...         ...       ...       ...       ...       ...       ...     ...  \n",
      "89729 -0.865154 -0.447115  0.862514  0.427892 -0.861142  1.264610     0.0  \n",
      "89730  1.390837 -0.447115  0.862514  0.427892 -0.861142  1.264610     0.0  \n",
      "89731 -0.865154 -0.447115  0.862514  0.427892  1.161248  1.264610     0.0  \n",
      "89732  0.262842  2.236560  0.862514 -2.337040 -0.861142  1.264610     0.0  \n",
      "89733 -0.865154 -0.447115 -0.546098 -2.337040 -0.861142  1.264610     0.0  \n",
      "\n",
      "[87350 rows x 21 columns]\n",
      "            ID         C         D         E         G         H         I  \\\n",
      "0          1.0 -0.851553  0.650218  1.024437  1.099090  3.209027  0.913155   \n",
      "1          2.0 -0.330364 -0.843031 -0.719023  1.099090  3.209027  0.913155   \n",
      "2          3.0 -0.851553 -0.469356 -0.449556  1.099090  3.209027  0.913155   \n",
      "3          4.0 -0.851553 -0.693866 -0.610402  1.099090  3.209027  0.913155   \n",
      "4          5.0 -0.851553  0.256104  0.387831  1.099090  3.209027  0.913155   \n",
      "...        ...       ...       ...       ...       ...       ...       ...   \n",
      "89729  89730.0 -0.590802 -0.126099 -0.502335  2.579008 -0.539453 -1.095105   \n",
      "89730  89731.0  1.025437  0.459962  0.301662  0.464839 -0.550224  0.913155   \n",
      "89731  89732.0 -0.548978  0.057296 -0.625598 -1.015080 -0.550224 -1.095105   \n",
      "89732  89733.0 -0.290208 -0.742627 -0.526987 -0.592246 -0.550224  0.913155   \n",
      "89733  89734.0 -0.252035 -0.844484 -0.840603 -1.015080 -0.550224 -1.095105   \n",
      "\n",
      "              J         L         M         N         O         R         S  \\\n",
      "0     -0.660309  0.282637  0.474695  0.710451  0.642038 -0.447115  0.862514   \n",
      "1     -0.705387 -0.975775  0.474695  0.710451  0.642038 -0.447115  0.862514   \n",
      "2     -0.224555 -0.326594  0.474695  0.710451 -1.551003 -0.447115 -0.546098   \n",
      "3      1.818981 -0.556304 -2.072290  0.710451 -1.551003 -0.447115 -0.546098   \n",
      "4      0.677005 -0.556304  0.474695  0.710451 -1.551003 -0.447115 -0.546098   \n",
      "...         ...       ...       ...       ...       ...       ...       ...   \n",
      "89729 -1.283888 -0.895876 -2.058774  0.710451  0.642038 -0.447115  0.862514   \n",
      "89730  0.316381 -0.556304  0.474695 -1.247629  0.642038 -0.447115  0.862514   \n",
      "89731  1.818981  1.840671  0.474695 -1.247629  0.642038 -0.447115  0.862514   \n",
      "89732 -1.103576 -0.736077  0.474695 -1.247629  0.642038  2.236560  0.862514   \n",
      "89733 -0.953316 -0.676153  0.474695 -1.247629 -1.486774 -0.447115 -0.546098   \n",
      "\n",
      "              W         X  MARKER  \n",
      "0      1.161248 -0.790758     0.0  \n",
      "1      1.161248 -0.790758     0.0  \n",
      "2      1.161248 -0.790758     0.0  \n",
      "3      1.161248 -0.790758     0.0  \n",
      "4     -0.861142 -0.790758     0.0  \n",
      "...         ...       ...     ...  \n",
      "89729 -0.861142  1.264610     0.0  \n",
      "89730 -0.861142  1.264610     0.0  \n",
      "89731  1.161248  1.264610     0.0  \n",
      "89732 -0.861142  1.264610     0.0  \n",
      "89733 -0.861142  1.264610     0.0  \n",
      "\n",
      "[87350 rows x 17 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\PycharmProjects\\innowise\\venv\\lib\\site-packages\\sklearn\\feature_selection\\_univariate_selection.py:113: RuntimeWarning: divide by zero encountered in divide\n",
      "  f = msb / msw\n"
     ]
    },
    {
     "data": {
      "text/plain": "'\\ntrain_data_copy, important_columns = select_features_pca(train_data_copy, train_data_copy[\"MARKER\"])\\nprint(train_data_copy)\\n'"
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# общий отбор признаков\n",
    "# Функция для удаления признаков с малым разнообразием значений\n",
    "def remove_low_variance_features(df, threshold=0.95, ignore_columns=[]):\n",
    "    num_rows = len(df)\n",
    "    columns_to_check = [col for col in df.columns if col not in ignore_columns]\n",
    "    low_variance_columns = [col for col in columns_to_check if (df[col].value_counts() / num_rows).max() > threshold]\n",
    "    df_filtered = df.drop(columns=low_variance_columns)\n",
    "    return df_filtered\n",
    "\n",
    "# Функция для удаления признаков с высокой корреляцией между собой\n",
    "def remove_high_correlation_features(df, y_df, threshold=0.8, ignore_columns=['ID', 'MARKER']):\n",
    "    corr_matrix = df.corr()  # Вычисляет матрицу корреляции для всех столбцов в df\n",
    "    to_drop = []  # Создает пустой список, в который будут добавляться столбцы для удаления\n",
    "\n",
    "    for column in corr_matrix.columns:  # Проходит по каждому столбцу матрицы корреляции\n",
    "        if column in ignore_columns:\n",
    "            continue  # Пропускает столбцы, указанные в ignore_columns\n",
    "\n",
    "        correlated_columns = corr_matrix.index[corr_matrix[column] > threshold].tolist()  # Находит список столбцов, которые сильно коррелируют с текущим столбцом\n",
    "        if correlated_columns:  # Если список сильно коррелирующих столбцов не пустой\n",
    "            max_corr_with_target = max(correlated_columns, key=lambda col: abs(df[column].corr(y_df)))\n",
    "            # Находит столбец с максимальной абсолютной корреляцией с целевым признаком y_df\n",
    "\n",
    "            if column != max_corr_with_target and max_corr_with_target not in ignore_columns:  # Добавляем проверку, чтобы игнорировать столбцы из ignore_columns\n",
    "                to_drop.append(column)  # Добавляет текущий столбец в список для удаления\n",
    "\n",
    "    df_filtered = df.drop(columns=to_drop)  # Удаляет столбцы из списка to_drop из исходного dataframe df\n",
    "    return df_filtered  # Возвращает новый dataframe с удаленными столбцами\n",
    "\n",
    "\n",
    "#Univariate feature selection\n",
    "\"\"\"\n",
    "def select_features_f_regression(X, y, k=10, ignore_columns=['ID', 'MARKER']):\n",
    "    selector = SelectKBest(score_func=f_regression, k=k)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "    # Создаем новый DataFrame с выбранными признаками\n",
    "    X_new_df = pd.DataFrame(X_new, columns=selected_features, index=X.index)\n",
    "\n",
    "    # Восстанавливаем игнорируемые столбцы на своих местах\n",
    "    for col in ignore_columns:\n",
    "        X_new_df[col] = X[col]\n",
    "\n",
    "    return X_new_df, selected_features\n",
    "\"\"\"\n",
    "\n",
    "def select_features_roc_auc(X, y, k=10, ignore_columns=['ID', 'MARKER']):\n",
    "    selector = SelectKBest(score_func=f_classif, k=k)\n",
    "    X_new = selector.fit_transform(X, y)\n",
    "    selected_features = X.columns[selector.get_support()]\n",
    "\n",
    "    X_new_df = pd.DataFrame(X_new, columns=selected_features, index=X.index)\n",
    "\n",
    "    for col in ignore_columns:\n",
    "        X_new_df[col] = X[col]\n",
    "\n",
    "    return X_new_df, selected_features\n",
    "\n",
    "\"\"\"\n",
    "def select_features_pca(X, y, variance_threshold=0.8, ignore_columns=['ID']):\n",
    "    # Удаляем столбец \"ID\" из X, если он присутствует\n",
    "    X = X.drop(columns=ignore_columns, errors='ignore')\n",
    "\n",
    "    # Создаем модель PCA, указываем, что мы хотим сохранить variance_threshold дисперсии\n",
    "    pca = PCA(n_components=variance_threshold, svd_solver='full')\n",
    "\n",
    "    # Применяем PCA на матрице признаков X\n",
    "    X_pca = pca.fit_transform(X)\n",
    "\n",
    "    # Создаем новый DataFrame с выбранными компонентами\n",
    "    selected_features = ['PCA_Component_{}'.format(i) for i in range(X_pca.shape[1])]\n",
    "    X_pca_df = pd.DataFrame(X_pca, columns=selected_features, index=X.index)\n",
    "\n",
    "    return X_pca_df, selected_features\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "train_data_copy = remove_low_variance_features(train_data_copy,threshold=0.85, ignore_columns=['ID', 'MARKER'])\n",
    "print(train_data_copy)\n",
    "\n",
    "train_data_copy = remove_high_correlation_features(train_data_copy,y_copy,threshold=0.75,ignore_columns=['ID', 'MARKER'])\n",
    "print(train_data_copy)\n",
    "\n",
    "train_data_copy,important_columns = select_features_roc_auc(train_data_copy, train_data_copy[\"MARKER\"], k=17)\n",
    "print(train_data_copy)\n",
    "\n",
    "\"\"\"\n",
    "train_data_copy, important_columns = select_features_pca(train_data_copy, train_data_copy[\"MARKER\"])\n",
    "print(train_data_copy)\n",
    "\"\"\"\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nfrom sklearn.metrics import roc_auc_score\\n\\ndef objective(trial, df, target_column_name, threshold, cv):\\n    penalty = trial.suggest_categorical(\\'penalty\\', [\\'l1\\', \\'l2\\'])\\n    C = trial.suggest_float(\\'C\\', 1e-2, 1e5, log=True)\\n\\n    X = df.iloc[:, 1:-1]\\n    y = df[target_column_name]\\n\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n    logreg = LogisticRegression(penalty=penalty, C=C, solver=\\'liblinear\\')\\n    logreg.fit(X_train, y_train)\\n\\n    y_pred = logreg.predict(X_test)\\n    roc_auc = roc_auc_score(y_test, y_pred)\\n\\n    return roc_auc\\n\\ndef build_logistic_regression_model(df, target_column_name, threshold=0.1, cv=5):\\n    sampler = optuna.samplers.RandomSampler()\\n\\n    study = optuna.create_study(direction=\\'maximize\\', sampler=sampler)\\n    study.optimize(lambda trial: objective(trial, df, target_column_name, threshold, cv), n_trials=50)\\n\\n    best_params = study.best_params\\n    best_penalty = best_params[\\'penalty\\']\\n    best_C = best_params[\\'C\\']\\n\\n    X = df.iloc[:, 1:-1]\\n    y = df[target_column_name]\\n\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n    logreg = LogisticRegression(penalty=best_penalty, C=best_C, solver=\\'liblinear\\')\\n    logreg.fit(X_train, y_train)\\n\\n    y_pred = logreg.predict(X_test)\\n    roc_auc = roc_auc_score(y_test, y_pred)\\n\\n    coefficients = logreg.coef_[0]\\n\\n    feature_names = X_train.columns\\n    coefficients_df = pd.DataFrame({\\'Feature\\': feature_names, \\'Coefficient\\': coefficients})\\n    coefficients_df = coefficients_df.reindex(coefficients_df[\\'Coefficient\\'].abs().sort_values(ascending=False).index)\\n\\n    selected_features = coefficients_df[coefficients_df[\\'Coefficient\\'].abs() > threshold][\\'Feature\\'].tolist()\\n\\n    X_train_selected = X_train[selected_features]\\n\\n    scores = cross_val_score(logreg, X_train_selected, y_train, cv=cv, error_score=\\'raise\\')\\n    average_score = scores.mean()\\n\\n    final_model = logreg.fit(X_train_selected, y_train)\\n\\n    return final_model, selected_features, average_score\\n\\n# Assuming train_data_copy contains your data\\nfinal_model, selected_features, average_score = build_logistic_regression_model(train_data_copy.drop(\\'ID\\', axis=1), target_column_name=\"MARKER\")\\nprint(\"Selected Features:\", selected_features)\\nprint(\"Average ROC AUC Score:\", average_score)\\n'"
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "def objective(trial, df, target_column_name, threshold, cv):\n",
    "    penalty = trial.suggest_categorical('penalty', ['l1', 'l2'])\n",
    "    C = trial.suggest_float('C', 1e-2, 1e5, log=True)\n",
    "\n",
    "    X = df.iloc[:, 1:-1]\n",
    "    y = df[target_column_name]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    logreg = LogisticRegression(penalty=penalty, C=C, solver='liblinear')\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    return roc_auc\n",
    "\n",
    "def build_logistic_regression_model(df, target_column_name, threshold=0.1, cv=5):\n",
    "    sampler = optuna.samplers.RandomSampler()\n",
    "\n",
    "    study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "    study.optimize(lambda trial: objective(trial, df, target_column_name, threshold, cv), n_trials=50)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_penalty = best_params['penalty']\n",
    "    best_C = best_params['C']\n",
    "\n",
    "    X = df.iloc[:, 1:-1]\n",
    "    y = df[target_column_name]\n",
    "\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    logreg = LogisticRegression(penalty=best_penalty, C=best_C, solver='liblinear')\n",
    "    logreg.fit(X_train, y_train)\n",
    "\n",
    "    y_pred = logreg.predict(X_test)\n",
    "    roc_auc = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "    coefficients = logreg.coef_[0]\n",
    "\n",
    "    feature_names = X_train.columns\n",
    "    coefficients_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "    coefficients_df = coefficients_df.reindex(coefficients_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "\n",
    "    selected_features = coefficients_df[coefficients_df['Coefficient'].abs() > threshold]['Feature'].tolist()\n",
    "\n",
    "    X_train_selected = X_train[selected_features]\n",
    "\n",
    "    scores = cross_val_score(logreg, X_train_selected, y_train, cv=cv, error_score='raise')\n",
    "    average_score = scores.mean()\n",
    "\n",
    "    final_model = logreg.fit(X_train_selected, y_train)\n",
    "\n",
    "    return final_model, selected_features, average_score\n",
    "\n",
    "# Assuming train_data_copy contains your data\n",
    "final_model, selected_features, average_score = build_logistic_regression_model(train_data_copy.drop('ID', axis=1), target_column_name=\"MARKER\")\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Average ROC AUC Score:\", average_score)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n# логистическая регрессия 2\\nimport numpy as np\\nimport pandas as pd\\nfrom sklearn.model_selection import train_test_split, GridSearchCV\\nfrom sklearn.linear_model import LogisticRegression\\nfrom sklearn.metrics import f1_score\\n\\ndef build_logistic_regression_model(df, target_column_name):\\n    # Выделите признаки и целевую переменную\\n    X = df.drop(columns=[\\'ID\\', target_column_name])\\n    y = df[target_column_name]\\n\\n    # Разделите данные на обучающий и тестовый наборы\\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\\n\\n    # Определите параметры для перебора\\n    param_grid = {\\n        \\'penalty\\': [\\'l1\\', \\'l2\\'],  # Перебор L1 и L2 регуляризации\\n        \\'C\\': np.logspace(-1, 1, 20)  # Перебор параметра регуляризации C\\n    }\\n\\n    # Создайте модель логистической регрессии с взвешиванием классов\\n    logreg = LogisticRegression(class_weight=\\'balanced\\', solver=\\'liblinear\\')\\n\\n    # Создайте объект GridSearchCV для перебора параметров\\n    grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring=\\'f1\\')\\n\\n    # Выполните поиск по сетке на обучающем наборе\\n    grid_search.fit(X_train, y_train)\\n\\n    # Получите наилучшие параметры и значение метрики f1_score\\n    best_params = grid_search.best_params_\\n    best_score = grid_search.best_score_\\n    print(\"Best Parameters:\", best_params)\\n    print(\"Best F1 Score:\", best_score)\\n\\n    # Получите наилучшую модель\\n    best_model = grid_search.best_estimator_\\n\\n    # Обучите модель на всем обучающем наборе\\n    best_model.fit(X_train, y_train)\\n\\n    # Предсказания для тестового набора\\n    y_pred = best_model.predict(X_test)\\n\\n    # Вычислите метрику F1-score на тестовом наборе\\n    test_f1_score = f1_score(y_test, y_pred)\\n    print(\"Test F1 Score:\", test_f1_score)\\n\\n    # Выведите коэффициенты модели\\n    coefficients = best_model.coef_[0]\\n    feature_names = X.columns\\n    coefficients_df = pd.DataFrame({\\'Feature\\': feature_names, \\'Coefficient\\': coefficients})\\n    coefficients_df = coefficients_df.reindex(coefficients_df[\\'Coefficient\\'].abs().sort_values(ascending=False).index)\\n    print(coefficients_df)\\n\\n    return best_model, coefficients_df\\n\\n# Пример использования:\\nfinal_model, coefficients = build_logistic_regression_model(train_data_copy, target_column_name=\"MARKER\")\\nprint(\"Selected Features:\", coefficients)\\n'"
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "# логистическая регрессия 2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def build_logistic_regression_model(df, target_column_name):\n",
    "    # Выделите признаки и целевую переменную\n",
    "    X = df.drop(columns=['ID', target_column_name])\n",
    "    y = df[target_column_name]\n",
    "\n",
    "    # Разделите данные на обучающий и тестовый наборы\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Определите параметры для перебора\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],  # Перебор L1 и L2 регуляризации\n",
    "        'C': np.logspace(-1, 1, 20)  # Перебор параметра регуляризации C\n",
    "    }\n",
    "\n",
    "    # Создайте модель логистической регрессии с взвешиванием классов\n",
    "    logreg = LogisticRegression(class_weight='balanced', solver='liblinear')\n",
    "\n",
    "    # Создайте объект GridSearchCV для перебора параметров\n",
    "    grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "    # Выполните поиск по сетке на обучающем наборе\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Получите наилучшие параметры и значение метрики f1_score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best F1 Score:\", best_score)\n",
    "\n",
    "    # Получите наилучшую модель\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Обучите модель на всем обучающем наборе\n",
    "    best_model.fit(X_train, y_train)\n",
    "\n",
    "    # Предсказания для тестового набора\n",
    "    y_pred = best_model.predict(X_test)\n",
    "\n",
    "    # Вычислите метрику F1-score на тестовом наборе\n",
    "    test_f1_score = f1_score(y_test, y_pred)\n",
    "    print(\"Test F1 Score:\", test_f1_score)\n",
    "\n",
    "    # Выведите коэффициенты модели\n",
    "    coefficients = best_model.coef_[0]\n",
    "    feature_names = X.columns\n",
    "    coefficients_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "    coefficients_df = coefficients_df.reindex(coefficients_df['Coefficient'].abs().sort_values(ascending=False).index)\n",
    "    print(coefficients_df)\n",
    "\n",
    "    return best_model, coefficients_df\n",
    "\n",
    "# Пример использования:\n",
    "final_model, coefficients = build_logistic_regression_model(train_data_copy, target_column_name=\"MARKER\")\n",
    "print(\"Selected Features:\", coefficients)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\n# Примените функцию для создания новой таблицы с балансированными классами\\ntrain_data_copy = perform_random_oversampling(train_data_copy, target_column_name=\"MARKER\")\\nprint(train_data_copy)\\ntrain_data_copy.to_csv(\"random_oversampling.csv\")\\n'"
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Oversampling\n",
    "\n",
    "def perform_random_oversampling(df, target_column_name):\n",
    "    # Выделите признаки и целевую переменную\n",
    "    \"\"\"\n",
    "    X = df.drop(columns=[target_column_name])\n",
    "    y = df[target_column_name]\n",
    "    \"\"\"\n",
    "    # Разделим данные по значениям целевой переменной\n",
    "    df_majority = df[df[target_column_name] == 0]\n",
    "    df_minority = df[df[target_column_name] == 1]\n",
    "\n",
    "    # Применим Random Over-sampling к классу с меньшим количеством записей\n",
    "    df_minority_upsampled = resample(df_minority, replace=True, n_samples=len(df_majority), random_state=42)\n",
    "\n",
    "    # Объединим балансированные классы\n",
    "    balanced_df = pd.concat([df_majority, df_minority_upsampled])\n",
    "\n",
    "    return balanced_df\n",
    "\n",
    "\"\"\"\n",
    "# Примените функцию для создания новой таблицы с балансированными классами\n",
    "train_data_copy = perform_random_oversampling(train_data_copy, target_column_name=\"MARKER\")\n",
    "print(train_data_copy)\n",
    "train_data_copy.to_csv(\"random_oversampling.csv\")\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Parameters: {'C': 0.008531678524172805, 'penalty': 'l1'}\n",
      "Best F1 Score: 0.026844778613515898\n",
      "Test F1 Score: 0.031982942430703626\n",
      "Selected Features:    Feature  Coefficient\n",
      "4        H     0.965258\n",
      "1        D     0.701302\n",
      "7        L    -0.626044\n",
      "9        N     0.554523\n",
      "11       R    -0.446009\n",
      "10       O    -0.441224\n",
      "13       W    -0.282629\n",
      "14       X    -0.211366\n",
      "8        M    -0.205839\n",
      "3        G    -0.197778\n",
      "Test Predictions: [0 1 0 ... 0 0 0]\n",
      "Test F1 Score (Threshold=0.965): 0.1111111111111111\n",
      "Test ROC AUC Score (Threshold=0.965): 0.8689360225743283\n"
     ]
    }
   ],
   "source": [
    "# логистическая регрессия 3\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "# ...\n",
    "\n",
    "def build_logistic_regression_model(df, target_column_name):\n",
    "    # Выделите признаки и целевую переменную\n",
    "    X = df.drop(columns=['ID', target_column_name])\n",
    "    y = df[target_column_name]\n",
    "\n",
    "    # Разделите данные на обучающий и тестовый наборы\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Определите параметры для перебора\n",
    "    param_grid = {\n",
    "        'penalty': ['l1', 'l2'],  # Перебор L1 и L2 регуляризации\n",
    "        'C': np.logspace(-4, 4, 30)  # Перебор параметра регуляризации C\n",
    "    }\n",
    "\n",
    "    # Создайте модель логистической регрессии\n",
    "    logreg = LogisticRegression(solver='liblinear', class_weight='balanced')\n",
    "\n",
    "    # Создайте объект GridSearchCV для перебора параметров\n",
    "    grid_search = GridSearchCV(logreg, param_grid, cv=5, scoring='f1')\n",
    "\n",
    "    # Выполните поиск по сетке на обучающем наборе\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Получите наилучшие параметры и значение метрики F1-score\n",
    "    best_params = grid_search.best_params_\n",
    "    best_score = grid_search.best_score_\n",
    "    print(\"Best Parameters:\", best_params)\n",
    "    print(\"Best F1 Score:\", best_score)\n",
    "\n",
    "    # Получите наилучшую модель\n",
    "    best_model = grid_search.best_estimator_\n",
    "\n",
    "    # Обучите модель на выбранных наиболее важных признаках\n",
    "    coefficients = best_model.coef_[0]\n",
    "    feature_names = X.columns\n",
    "    coefficients_df = pd.DataFrame({'Feature': feature_names, 'Coefficient': coefficients})\n",
    "\n",
    "    # Отберите 10 наиболее важных признаков\n",
    "    top_features = coefficients_df.iloc[np.abs(coefficients_df['Coefficient']).nlargest(10).index]\n",
    "    selected_features = top_features['Feature'].tolist()\n",
    "    X_train_selected = X_train[selected_features]\n",
    "    X_test_selected = X_test[selected_features]\n",
    "\n",
    "    # Обучение модели на выбранных признаках\n",
    "    best_model.fit(X_train_selected, y_train)\n",
    "\n",
    "    # Предсказания для тестового набора\n",
    "    y_pred = best_model.predict(X_test_selected)\n",
    "\n",
    "    # Вычислите метрику F1-score на тестовом наборе\n",
    "    test_f1_score = f1_score(y_test, y_pred)\n",
    "    print(\"Test F1 Score:\", test_f1_score)\n",
    "\n",
    "    return best_model, top_features\n",
    "\n",
    "\n",
    "def evaluate_with_threshold(model, test_data, target_column_name, selected_features, threshold=0.5):\n",
    "    # Выделите признаки из test данных\n",
    "    test_X = test_data[selected_features]\n",
    "\n",
    "    # Получите вероятности для класса 1\n",
    "    test_probabilities = model.predict_proba(test_X)[:, 1]\n",
    "\n",
    "    # Примените порог вероятности для получения предсказаний (0 или 1)\n",
    "    test_predictions = (test_probabilities > threshold).astype(int)\n",
    "\n",
    "    # Создайте DataFrame с предсказанными значениями\n",
    "    predictions_df = pd.DataFrame({'Prediction': test_predictions})\n",
    "\n",
    "    # Запишите DataFrame в CSV-файл\n",
    "    predictions_df.to_csv(\"predictions.csv\", index=False)\n",
    "\n",
    "    target_data = test_data[target_column_name]\n",
    "\n",
    "    # Вычислим метрику F1-score на test данных\n",
    "    test_f1 = f1_score(target_data, test_predictions)\n",
    "\n",
    "    # Вычислим метрику ROC AUC на test данных\n",
    "    test_roc_auc = roc_auc_score(target_data, test_probabilities)\n",
    "\n",
    "    return test_predictions, test_f1, test_roc_auc\n",
    "\n",
    "\n",
    "\n",
    "final_model, coefficients = build_logistic_regression_model(train_data_copy, target_column_name=\"MARKER\")\n",
    "print(\"Selected Features:\", coefficients)\n",
    "\n",
    "# Получите список выбранных признаков\n",
    "selected_features = coefficients['Feature'].tolist()\n",
    "\n",
    "# Используйте разные значения порога вероятности и смотрите, как изменяются метрики\n",
    "threshold = 0.965  # Пример значения порога\n",
    "test_predictions, test_f1_score, test_roc_auc = evaluate_with_threshold(final_model, test_data_copy, target_column_name=\"MARKER\", selected_features=selected_features, threshold=threshold)\n",
    "print(\"Test Predictions:\", test_predictions)\n",
    "print(\"Test F1 Score (Threshold={}):\".format(threshold), test_f1_score)\n",
    "print(\"Test ROC AUC Score (Threshold={}):\".format(threshold), test_roc_auc)\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "data": {
      "text/plain": "'\\nfinal_model, selected_features, average_score = build_random_forest_model(train_data_copy.drop(\\'ID\\', axis=1), target_column_name=\"MARKER\",selected_features= selected_features)\\nprint(\"Selected Features:\", selected_features)\\nprint(\"Average Cross-Validation Score:\", average_score)\\n'"
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# случайный лес\n",
    "\n",
    "def objective(trial, df, target_column_name, cv):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 750, step= 100)\n",
    "    max_depth = trial.suggest_int('max_depth',3, 15)\n",
    "    min_samples_split = trial.suggest_float('min_samples_split', 0.05, 1.0)\n",
    "    min_samples_leaf = trial.suggest_float('min_samples_leaf', 0.05, 0.5)\n",
    "\n",
    "\n",
    "    X = df.iloc[:, :-1]\n",
    "    y = df[target_column_name]\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "    n_estimators=n_estimators,\n",
    "    max_depth=max_depth,\n",
    "    min_samples_split=min_samples_split,\n",
    "    min_samples_leaf=min_samples_leaf,\n",
    "    class_weight='balanced',  # Добавьте этот параметр\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "    scores = cross_val_score(model, X, y, cv=cv)\n",
    "    average_score = scores.mean()\n",
    "\n",
    "    return average_score\n",
    "\n",
    "# ...\n",
    "\n",
    "def build_random_forest_model(df, target_column_name, cv=5, selected_features=None):\n",
    "    sampler = TPESampler()\n",
    "\n",
    "    study = optuna.create_study(direction='maximize', sampler=sampler)\n",
    "    study.optimize(lambda trial: objective(trial, df, target_column_name, cv), n_trials=40)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_n_estimators = best_params['n_estimators']\n",
    "    best_max_depth = best_params['max_depth']\n",
    "    best_min_samples_split = best_params['min_samples_split']\n",
    "    best_min_samples_leaf = best_params['min_samples_leaf']\n",
    "\n",
    "    X = df.iloc[:, :-1]\n",
    "\n",
    "    if selected_features is not None:\n",
    "        print(\"Selected Features:\", selected_features)\n",
    "        X = X[selected_features]\n",
    "\n",
    "    y = df[target_column_name]\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=best_n_estimators,\n",
    "        max_depth=best_max_depth,\n",
    "        min_samples_split=best_min_samples_split,\n",
    "        min_samples_leaf=best_min_samples_leaf,\n",
    "        class_weight='balanced',  # Добавьте этот параметр\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X, y)\n",
    "\n",
    "    feature_importances = model.feature_importances_\n",
    "    feature_names = X.columns\n",
    "    feature_importance_df = pd.DataFrame({'Feature': feature_names, 'Importance': feature_importances})\n",
    "    print(feature_importance_df)\n",
    "    #selected_features = feature_importance_df[feature_importance_df['Importance'] > 0]['Feature'].tolist()\n",
    "    selected_features = feature_importance_df['Feature'].tolist()\n",
    "    print(selected_features)\n",
    "    \"\"\"\n",
    "    if len(selected_features) > 0:\n",
    "        X_selected = X[selected_features]\n",
    "        scores = cross_val_score(model, X_selected, y, cv=cv)\n",
    "        average_score = scores.mean()\n",
    "    else:\n",
    "        average_score = 0.0  # Произвольное значение для случая, когда нет выбранных признаков\n",
    "    \"\"\"\n",
    "    X_selected = X[selected_features]\n",
    "    scores = cross_val_score(model, X_selected, y, cv=cv)\n",
    "    average_score = scores.mean()\n",
    "    return model, selected_features, average_score\n",
    "\n",
    "\"\"\"\n",
    "final_model, selected_features, average_score = build_random_forest_model(train_data_copy.drop('ID', axis=1), target_column_name=\"MARKER\",selected_features= selected_features)\n",
    "print(\"Selected Features:\", selected_features)\n",
    "print(\"Average Cross-Validation Score:\", average_score)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-18 17:08:34,178] A new study created in memory with name: no-name-b372f5db-3bcf-4f9c-9be5-91475876b044\n",
      "[I 2023-08-18 17:08:48,698] Trial 0 finished with value: 0.5 and parameters: {'n_estimators': 650, 'max_depth': 8, 'min_samples_split': 0.8669208084422814, 'min_samples_leaf': 0.258544931121563}. Best is trial 0 with value: 0.5.\n",
      "[I 2023-08-18 17:08:52,161] Trial 1 finished with value: 0.5 and parameters: {'n_estimators': 150, 'max_depth': 19, 'min_samples_split': 0.764663042959327, 'min_samples_leaf': 0.07191752905955787}. Best is trial 0 with value: 0.5.\n",
      "[I 2023-08-18 17:09:18,028] Trial 2 finished with value: 0.8334711290696353 and parameters: {'n_estimators': 550, 'max_depth': 20, 'min_samples_split': 0.1840716659403735, 'min_samples_leaf': 0.15737464519376956}. Best is trial 2 with value: 0.8334711290696353.\n",
      "[I 2023-08-18 17:09:20,050] Trial 3 finished with value: 0.8025650262473274 and parameters: {'n_estimators': 50, 'max_depth': 8, 'min_samples_split': 0.05011218317044941, 'min_samples_leaf': 0.26497364760180886}. Best is trial 2 with value: 0.8334711290696353.\n",
      "[I 2023-08-18 17:09:36,037] Trial 4 finished with value: 0.8404526546862485 and parameters: {'n_estimators': 350, 'max_depth': 24, 'min_samples_split': 0.4228346701580184, 'min_samples_leaf': 0.09067699070538981}. Best is trial 4 with value: 0.8404526546862485.\n",
      "[I 2023-08-18 17:09:43,674] Trial 5 finished with value: 0.8384678350906333 and parameters: {'n_estimators': 150, 'max_depth': 19, 'min_samples_split': 0.2936887017776219, 'min_samples_leaf': 0.12175240692300689}. Best is trial 4 with value: 0.8404526546862485.\n",
      "[I 2023-08-18 17:09:47,098] Trial 6 finished with value: 0.5 and parameters: {'n_estimators': 150, 'max_depth': 4, 'min_samples_split': 0.9340811754167692, 'min_samples_leaf': 0.32549886619498275}. Best is trial 4 with value: 0.8404526546862485.\n",
      "[I 2023-08-18 17:10:04,258] Trial 7 finished with value: 0.5 and parameters: {'n_estimators': 750, 'max_depth': 12, 'min_samples_split': 0.8930327584756352, 'min_samples_leaf': 0.07547717967557871}. Best is trial 4 with value: 0.8404526546862485.\n",
      "[I 2023-08-18 17:10:12,292] Trial 8 finished with value: 0.5 and parameters: {'n_estimators': 350, 'max_depth': 19, 'min_samples_split': 0.6416169101988772, 'min_samples_leaf': 0.4770534302439092}. Best is trial 4 with value: 0.8404526546862485.\n",
      "[I 2023-08-18 17:10:15,914] Trial 9 finished with value: 0.5 and parameters: {'n_estimators': 150, 'max_depth': 12, 'min_samples_split': 0.4277059797920659, 'min_samples_leaf': 0.37702873074521454}. Best is trial 4 with value: 0.8404526546862485.\n",
      "[I 2023-08-18 17:10:33,165] Trial 10 finished with value: 0.8234299234769725 and parameters: {'n_estimators': 450, 'max_depth': 25, 'min_samples_split': 0.4917257291659399, 'min_samples_leaf': 0.18809270447876641}. Best is trial 4 with value: 0.8404526546862485.\n",
      "[I 2023-08-18 17:10:51,345] Trial 11 finished with value: 0.8419161152473542 and parameters: {'n_estimators': 350, 'max_depth': 25, 'min_samples_split': 0.3277365310547191, 'min_samples_leaf': 0.05708538506439029}. Best is trial 11 with value: 0.8419161152473542.\n",
      "[I 2023-08-18 17:11:07,933] Trial 12 finished with value: 0.8417174788242235 and parameters: {'n_estimators': 350, 'max_depth': 25, 'min_samples_split': 0.37269580650993506, 'min_samples_leaf': 0.0596748754129066}. Best is trial 11 with value: 0.8419161152473542.\n",
      "[I 2023-08-18 17:11:31,753] Trial 13 finished with value: 0.8419367197018118 and parameters: {'n_estimators': 450, 'max_depth': 23, 'min_samples_split': 0.30324197332838176, 'min_samples_leaf': 0.05629573480714263}. Best is trial 13 with value: 0.8419367197018118.\n",
      "[I 2023-08-18 17:11:52,315] Trial 14 finished with value: 0.8318573042114471 and parameters: {'n_estimators': 450, 'max_depth': 22, 'min_samples_split': 0.2841842346759946, 'min_samples_leaf': 0.1721114918061099}. Best is trial 13 with value: 0.8419367197018118.\n",
      "[I 2023-08-18 17:12:13,189] Trial 15 finished with value: 0.8380108266348014 and parameters: {'n_estimators': 550, 'max_depth': 15, 'min_samples_split': 0.5657924889922002, 'min_samples_leaf': 0.051300168651389394}. Best is trial 13 with value: 0.8419367197018118.\n",
      "[I 2023-08-18 17:12:25,979] Trial 16 finished with value: 0.840265597419933 and parameters: {'n_estimators': 250, 'max_depth': 16, 'min_samples_split': 0.15742448084081984, 'min_samples_leaf': 0.12893744564438303}. Best is trial 13 with value: 0.8419367197018118.\n",
      "[I 2023-08-18 17:12:47,499] Trial 17 finished with value: 0.8197046513211991 and parameters: {'n_estimators': 550, 'max_depth': 22, 'min_samples_split': 0.34802216230206384, 'min_samples_leaf': 0.19622903328305294}. Best is trial 13 with value: 0.8419367197018118.\n",
      "[I 2023-08-18 17:12:56,812] Trial 18 finished with value: 0.8373864982456956 and parameters: {'n_estimators': 250, 'max_depth': 22, 'min_samples_split': 0.5317139209693806, 'min_samples_leaf': 0.12377777764958152}. Best is trial 13 with value: 0.8419367197018118.\n",
      "[I 2023-08-18 17:13:21,398] Trial 19 finished with value: 0.8418356362846012 and parameters: {'n_estimators': 450, 'max_depth': 16, 'min_samples_split': 0.24469238451755287, 'min_samples_leaf': 0.10448813518648611}. Best is trial 13 with value: 0.8419367197018118.\n",
      "[I 2023-08-18 17:13:45,259] Trial 20 finished with value: 0.8197767970125417 and parameters: {'n_estimators': 650, 'max_depth': 23, 'min_samples_split': 0.3707776882746243, 'min_samples_leaf': 0.2185857768642879}. Best is trial 13 with value: 0.8419367197018118.\n",
      "[I 2023-08-18 17:14:10,477] Trial 21 finished with value: 0.8413085725977117 and parameters: {'n_estimators': 450, 'max_depth': 17, 'min_samples_split': 0.21583304707993603, 'min_samples_leaf': 0.10630736253101736}. Best is trial 13 with value: 0.8419367197018118.\n",
      "[I 2023-08-18 17:14:24,605] Trial 22 finished with value: 0.8437420054072916 and parameters: {'n_estimators': 250, 'max_depth': 13, 'min_samples_split': 0.25868453953472526, 'min_samples_leaf': 0.052086204960974596}. Best is trial 22 with value: 0.8437420054072916.\n",
      "[I 2023-08-18 17:14:41,316] Trial 23 finished with value: 0.8459633441566252 and parameters: {'n_estimators': 250, 'max_depth': 12, 'min_samples_split': 0.1494115969621784, 'min_samples_leaf': 0.061102276838158165}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:14:53,428] Trial 24 finished with value: 0.8386057363773023 and parameters: {'n_estimators': 250, 'max_depth': 12, 'min_samples_split': 0.1184281583574135, 'min_samples_leaf': 0.14046344627899573}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:14:56,634] Trial 25 finished with value: 0.8423124287077108 and parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 0.22422383341705282, 'min_samples_leaf': 0.050775197550461705}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:15:11,492] Trial 26 finished with value: 0.8427163355617384 and parameters: {'n_estimators': 250, 'max_depth': 9, 'min_samples_split': 0.10389557974672298, 'min_samples_leaf': 0.0967244396494699}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:15:25,784] Trial 27 finished with value: 0.8421533836498402 and parameters: {'n_estimators': 250, 'max_depth': 4, 'min_samples_split': 0.06766676759133623, 'min_samples_leaf': 0.10125291651702059}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:15:37,366] Trial 28 finished with value: 0.8341397298029912 and parameters: {'n_estimators': 250, 'max_depth': 8, 'min_samples_split': 0.12305741401862516, 'min_samples_leaf': 0.1547437420556967}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:15:40,498] Trial 29 finished with value: 0.841963552899546 and parameters: {'n_estimators': 50, 'max_depth': 6, 'min_samples_split': 0.1317979367509738, 'min_samples_leaf': 0.0935976331628916}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:15:46,109] Trial 30 finished with value: 0.8232780886165895 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 0.17820812423194132, 'min_samples_leaf': 0.21746960152946548}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:15:49,092] Trial 31 finished with value: 0.8413807112350546 and parameters: {'n_estimators': 50, 'max_depth': 10, 'min_samples_split': 0.2415809399341099, 'min_samples_leaf': 0.09249003258463623}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:15:57,873] Trial 32 finished with value: 0.8427144945744368 and parameters: {'n_estimators': 150, 'max_depth': 10, 'min_samples_split': 0.22201803591062094, 'min_samples_leaf': 0.07818531114888633}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:16:07,418] Trial 33 finished with value: 0.844026747423084 and parameters: {'n_estimators': 150, 'max_depth': 14, 'min_samples_split': 0.09450066955696737, 'min_samples_leaf': 0.08141204747508232}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:16:20,083] Trial 34 finished with value: 0.8404146460853319 and parameters: {'n_estimators': 250, 'max_depth': 14, 'min_samples_split': 0.05407243223654763, 'min_samples_leaf': 0.13304434299196174}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:16:41,671] Trial 35 finished with value: 0.8436147594997895 and parameters: {'n_estimators': 350, 'max_depth': 13, 'min_samples_split': 0.10073405114936301, 'min_samples_leaf': 0.08898717789659613}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:16:58,349] Trial 36 finished with value: 0.8342531912462675 and parameters: {'n_estimators': 350, 'max_depth': 13, 'min_samples_split': 0.16937457720627452, 'min_samples_leaf': 0.15427222907704036}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:17:20,726] Trial 37 finished with value: 0.8449315709138749 and parameters: {'n_estimators': 350, 'max_depth': 17, 'min_samples_split': 0.086013436488161, 'min_samples_leaf': 0.07960156049662279}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:17:30,650] Trial 38 finished with value: 0.8444864662991078 and parameters: {'n_estimators': 150, 'max_depth': 17, 'min_samples_split': 0.050331821193733965, 'min_samples_leaf': 0.07359859104526018}. Best is trial 23 with value: 0.8459633441566252.\n",
      "[I 2023-08-18 17:17:40,438] Trial 39 finished with value: 0.8440992730443464 and parameters: {'n_estimators': 150, 'max_depth': 18, 'min_samples_split': 0.053330449428326265, 'min_samples_leaf': 0.07450427662827656}. Best is trial 23 with value: 0.8459633441566252.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC AUC: 0.7638537552449831\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "         0.0       1.00      0.73      0.85     38259\n",
      "         1.0       0.01      0.79      0.02       146\n",
      "\n",
      "    accuracy                           0.73     38405\n",
      "   macro avg       0.51      0.76      0.43     38405\n",
      "weighted avg       1.00      0.73      0.84     38405\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# случайный лес 2\n",
    "def objective(trial, X, y):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 50, 750, step=100)\n",
    "    max_depth = trial.suggest_int('max_depth', 3, 25)\n",
    "    min_samples_split = trial.suggest_float('min_samples_split', 0.05, 1.0)\n",
    "    min_samples_leaf = trial.suggest_float('min_samples_leaf', 0.05, 0.5)\n",
    "\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=n_estimators,\n",
    "        max_depth=max_depth,\n",
    "        min_samples_split=min_samples_split,\n",
    "        min_samples_leaf=min_samples_leaf,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    scores = cross_val_score(model, X, y, cv=skf, scoring='roc_auc')\n",
    "    average_score = scores.mean()\n",
    "\n",
    "    return average_score\n",
    "\n",
    "def build_and_predict_random_forest(train_data, test_data, target_column_name, selected_features):\n",
    "    # Выделите признаки и целевую переменную\n",
    "    X_train = train_data[selected_features]\n",
    "    y_train = train_data[target_column_name]\n",
    "    X_test = test_data[selected_features]\n",
    "    y_test = test_data[target_column_name]\n",
    "\n",
    "    # Подбор гиперпараметров\n",
    "    study = optuna.create_study(direction='maximize')\n",
    "    study.optimize(lambda trial: objective(trial, X_train, y_train), n_trials=40)\n",
    "\n",
    "    best_params = study.best_params\n",
    "    best_n_estimators = best_params['n_estimators']\n",
    "    best_max_depth = best_params['max_depth']\n",
    "    best_min_samples_split = best_params['min_samples_split']\n",
    "    best_min_samples_leaf = best_params['min_samples_leaf']\n",
    "\n",
    "    # Создайте и обучите модель случайного леса с наилучшими гиперпараметрами\n",
    "    model = RandomForestClassifier(\n",
    "        n_estimators=best_n_estimators,\n",
    "        max_depth=best_max_depth,\n",
    "        min_samples_split=best_min_samples_split,\n",
    "        min_samples_leaf=best_min_samples_leaf,\n",
    "        class_weight='balanced',\n",
    "        random_state=42\n",
    "    )\n",
    "    model.fit(X_train, y_train)\n",
    "\n",
    "    # Прогнозирование на тестовых данных\n",
    "    test_predictions = model.predict(X_test)\n",
    "\n",
    "    # Вычисление метрик\n",
    "    roc_auc = roc_auc_score(y_test, test_predictions)\n",
    "    classification_rep = classification_report(y_test, test_predictions)\n",
    "\n",
    "    print(\"ROC AUC:\", roc_auc)\n",
    "    print(\"Classification Report:\\n\", classification_rep)\n",
    "\n",
    "    return model\n",
    "\n",
    "# Построение и оценка модели случайного леса\n",
    "model = build_and_predict_random_forest(train_data_copy, test_data_copy, \"MARKER\", selected_features)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2023-08-18 17:17:44,814] A new study created in memory with name: no-name-0f050778-b8e5-4f31-921c-3f36dd501174\n",
      "[I 2023-08-18 17:17:48,373] Trial 0 finished with value: 0.0 and parameters: {'n_estimators': 15, 'learning_rate': 0.1889200856555388}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-08-18 17:17:49,590] Trial 1 finished with value: 0.0 and parameters: {'n_estimators': 5, 'learning_rate': 0.40377956454702535}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-08-18 17:17:54,265] Trial 2 finished with value: 0.0 and parameters: {'n_estimators': 20, 'learning_rate': 0.001626343175952954}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-08-18 17:17:56,663] Trial 3 finished with value: 0.0 and parameters: {'n_estimators': 10, 'learning_rate': 0.04067092448908578}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-08-18 17:18:03,658] Trial 4 finished with value: 0.0 and parameters: {'n_estimators': 30, 'learning_rate': 0.001757059909770206}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-08-18 17:18:06,042] Trial 5 finished with value: 0.0 and parameters: {'n_estimators': 10, 'learning_rate': 0.03130494109874759}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-08-18 17:18:09,600] Trial 6 finished with value: 0.0 and parameters: {'n_estimators': 15, 'learning_rate': 0.9409718244367576}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-08-18 17:18:13,130] Trial 7 finished with value: 0.0 and parameters: {'n_estimators': 15, 'learning_rate': 0.003843240812289111}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-08-18 17:18:16,683] Trial 8 finished with value: 0.0 and parameters: {'n_estimators': 15, 'learning_rate': 0.08666896160905946}. Best is trial 0 with value: 0.0.\n",
      "[I 2023-08-18 17:18:21,367] Trial 9 finished with value: 0.0 and parameters: {'n_estimators': 20, 'learning_rate': 0.007479549822070128}. Best is trial 0 with value: 0.0.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimal Hyperparameters: {'n_estimators': 15, 'learning_rate': 0.1889200856555388}\n",
      "Test F1 Score: 0.0\n",
      "Test AUC-ROC Score: 0.5\n"
     ]
    }
   ],
   "source": [
    "# ADABoosting\n",
    "\n",
    "# Загрузите свои данные в переменную train_data_copy\n",
    "\n",
    "# Выделите признаки и целевую переменную\n",
    "X = train_data_copy.drop(columns=['ID', 'MARKER'])\n",
    "y = train_data_copy['MARKER']\n",
    "\n",
    "# Разбейте данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Определите целевую функцию для оптимизации гиперпараметров\n",
    "def objective(trial):\n",
    "    n_estimators = trial.suggest_int('n_estimators', 5, 30, step=5)\n",
    "    learning_rate = trial.suggest_float('learning_rate', 0.001, 1.0, log=True)\n",
    "\n",
    "    model = AdaBoostClassifier(n_estimators=n_estimators, learning_rate=learning_rate, random_state=42)\n",
    "    scores = cross_val_score(model, X_train, y_train, cv=5, scoring='f1')\n",
    "    return np.mean(scores)\n",
    "\n",
    "# Создайте объект study для оптимизации\n",
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)\n",
    "\n",
    "# Получите оптимальные параметры\n",
    "best_params = study.best_params\n",
    "\n",
    "# Создайте модель AdaBoostClassifier с оптимальными параметрами\n",
    "optimal_model = AdaBoostClassifier(n_estimators=best_params['n_estimators'], learning_rate=best_params['learning_rate'], random_state=42)\n",
    "\n",
    "# Обучите модель на полной обучающей выборке\n",
    "optimal_model.fit(X_train, y_train)\n",
    "\n",
    "# Оцените F1-меру и AUC-ROC Score на тестовой выборке\n",
    "y_pred = optimal_model.predict(X_test)\n",
    "test_f1_score = f1_score(y_test, y_pred)\n",
    "test_auc_score = roc_auc_score(y_test, y_pred)\n",
    "\n",
    "print(\"Optimal Hyperparameters:\", best_params)\n",
    "print(\"Test F1 Score:\", test_f1_score)\n",
    "print(\"Test AUC-ROC Score:\", test_auc_score)\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}